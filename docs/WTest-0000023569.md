# W-Test

### W-Test

A rejection of the F-Test does not directly indicate the reason for the rejection itself. Thus, in case the null-hypothesis is rejected, other hypotheses must be formulated if you want to describe a possible error or a combination of errors.

There is an infinite number of hypotheses which you could formulate as an alternative for the null-hypothesis. But the more complex these hypotheses become the more difficult they are to interpret. A simple but effective hypothesis, though, is the so-called conventional alternative hypothesis, based on the assumption that you have to suspect an outlier in only one observation while all others are correct. The one-dimensional test associated with this hypothesis is called W-Test.

The assumption that just a single outlier corrupts your network is, indeed realistic. A strong rejection of the F-Test can often be traced back to a gross error in just one observation. The conventional alternative hypothesis for each observation implies that each individual observation is tested. The process of testing each observation in a network by a W-Test is called data snooping.

Often the size of the least squares correction alone is not precise enough to indicate an outlier when you check the observations in your network. A better test quantity, though only suited for uncorrelated observations, is the least squares correction divided by its standard deviation. For correlated observations, like for example the three coordinate elements of a baseline, the complete weight matrix of the observations must be taken into account. This condition is fulfilled with the test quantity W of the W-Test, which has a standard normal distribution and is most sensitive to errors in one of the observations.

The critical value Wcrit depends on your choice of the significance level α0. If the W-Test is rejected because of W>Wcrit, there is a probability of 1-α0 that the corresponding observation indeed holds an outlier. On the other hand, there is a probability of α0 that the observation does not hold an outlier, which implies that the rejection was unjustified. In geodesy, values for α0 between 0.001 and 0.05 are most commonly used. The following table gives you an overview on the α0-values and their corresponding critical values. Which α0 you effectively choose depending on how strict and rigid you intend to test your observations. A strict testing (with a small critical value), leads to a larger α0 and therefore, to an increased probability to reject valid observations. An α0 value of 0.001 implies one false rejection in every 1000 observations. This has proven to be a realistic choice.

| significance level α0 | 0.001 | 0.010 | 0.050 |
| --- | --- | --- | --- |
| critical value W-Test | 3.29 | 2.58 | 1.96 |

**significance level α0**

**critical value W-Test**

Essential for a successful testing by the B-Method is that an outlier is detected with the same probability by both the F-Test and the W-Test. To achieve this, the test power β is by default fixed on a level of usually 0.80 for both tests. You can adapt β by 10% up or down in the settings for the test criteria. The W-Test level of significance α0 is selected, to which leaves the F-Test level of significance α to be determined. With α0 and β being fixed, α strongly depends on the redundancy in the network and increases for large networks with many observations and a considerable amount of redundancy. In such networks, it becomes difficult for the F-Test to react on a single outlier. The F-Test, being an overall model test, is not sensitive enough to achieve this task. Thus, it is common practice to do data snooping, no matter what the result of the F-Test might be.

See also:

**See also:**

Test Criteria

